{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from Engine.Engine import Value, Neuron, Layer, Visualizer, MLP\n",
    "from Engine.MLUtils import printPurple\n",
    "\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value(data=2, grad=1)\n"
     ]
    }
   ],
   "source": [
    "# testing imports\n",
    "v = Value(1) ; v.label = \"v\"\n",
    "v2 = Value(2) ;  v2.label = \"v2\"\n",
    "v3 = v * v2 ; v3.label = \"v3\"\n",
    "\n",
    "v3.backward()\n",
    "\n",
    "print(v3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (60000, 28, 28)\n",
      "Y_train: (60000,)\n",
      "X_test:  (10000, 28, 28)\n",
      "Y_test:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "# import Data\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "print('X_train: ' + str(train_X.shape))\n",
    "print('Y_train: ' + str(train_y.shape))\n",
    "print('X_test:  '  + str(test_X.shape))\n",
    "print('Y_test:  '  + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJwAAACbCAYAAACXvfL1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAALvElEQVR4nO3dbWxT5RsG8GudtAPdOifZZmXNplHwJUKyrGVIfJ2ZGIkgfoAvaiAsYGskGj5IVCJRZ3wLGY6oia5igiN8EBQTNdkYRGWQTWcyahZNSJiyzqCu3XjZpL3/H5Dz5zmFrd3Onp7S65ecpHdPX56wi3NOz8t98kREQKSJI9MDoNzCwJFWDBxpxcCRVgwcacXAkVYMHGnFwJFWDBxpxcCRVtMWuObmZlRWVqKgoAB+vx9HjhyZrq+iLJI3HcdSd+3ahSeeeALvv/8+/H4/tm7dit27d6Ovrw+lpaXjvjeRSODEiRMoLCxEXl6e1UOjaSAiGB4ehsfjgcMxwTJMpoHP55NAIGDU8XhcPB6PNDY2Tvje/v5+AcApC6f+/v4J/76Wr1LHxsbQ3d2Nuro64zmHw4G6ujocOnQo6fWjo6OIxWLGJDx5JWsVFhZO+BrLA3fy5EnE43GUlZUpz5eVlSESiSS9vrGxEW6325i8Xq/VQyJNUtkEyviv1BdeeAHRaNSY+vv7Mz0kmkZXWf2Bs2fPRn5+PgYHB5XnBwcHUV5envR6l8sFl8tl9TDIpixfwjmdTlRXV6Otrc14LpFIoK2tDbW1tVZ/HWWbqfwavZzW1lZxuVwSCoUkHA5LQ0ODFBcXSyQSmfC90Wg047+2OE1uikajE/59pyVwIiLbtm0Tr9crTqdTfD6fdHZ2pvQ+Bi57p1QCNy07fqciFovB7XZnehg0CdFoFEVFReO+JuO/Uim3MHCkFQNHWjFwpBUDR1oxcKQVA0daMXCkFQNHWll+tkiuy8/PV+p0jpoEg0GlnjVrllLPnTtXqQOBgFK//fbbSr1q1SqlPnv2rFK/8cYbxuNXXnkl5XFOBZdwpBUDR1oxcKQVt+FMzNdUOJ1OpV60aJFSL168WKmLi4uVesWKFZaN7ffff1fqpqYmpV6+fLlSDw8PK/XPP/+s1AcOHLBsbKniEo60YuBIKwaOtMr5M34XLFig1O3t7UqdybOPE4mEUq9evVqpR0ZGxn3/wMCAUv/zzz9K3dfXN4XRJeMZv2Q7DBxpxcCRVjm/H+748eNK/ddffym1ldtwhw8fVuqhoSGlvu+++5R6bGxMqT/99FPLxpIpXMKRVgwcacXAkVY5vw33999/K/XGjRuV+pFHHlHqn376SanNxzPNenp6jMcPPvigMu/UqVNKffvttyv1s88+O+5nZyMu4UgrBo60SjtwBw8exNKlS+HxeJCXl4c9e/Yo80UEL7/8Mq6//nrMnDkTdXV1+PXXX60aL2W5tLfhTp06hfnz52P16tV47LHHkua/+eabaGpqwieffIKqqiq89NJLqK+vRzgcRkFBgSWDnk7m/0DmY6vmc8zmz5+v1GvWrFHqi68zMG+zmR09elSpGxoaxn19Nko7cEuWLMGSJUsuOU9EsHXrVrz44ot49NFHAQA7duxAWVkZ9uzZg5UrVya9Z3R0FKOjo0Ydi8XSHRJlEUu34Y4dO4ZIJKK0zHe73fD7/ZdsmQ8kdzGvqKiwckhkM5YG7kJb/FRb5gPsYp5rMr4fzu5dzCdaxUej0XHnr1271ni8a9cuZZ75fLdcYOkS7kJb/FRb5lPusTRwVVVVKC8vV1rmx2IxHD58mC3zCcAkVqkjIyP47bffjPrYsWPo6elBSUkJvF4vNmzYgFdffRU333yzsVvE4/Fg2bJlVo6bslTa1zR0dHQknbcFAE8++SRCoRBEBJs3b8aHH36IoaEhLF68GNu3b8ctt9yS0udnWxfzq6++Wqm//PJLpb7nnnuMx+bdSd9+++30DSwDUrmmIe0l3L333jvuHf/y8vKwZcsWbNmyJd2PphzAY6mkFQNHWuX8dalWu+mmm5T6xx9/NB6br2HYv3+/Und1dSl1c3OzUtvsT5WE16WS7TBwpBVXqdPs4hZaLS0tyryJ7hG/adMmpd6xY4dSm1s5ZBpXqWQ7DBxpxcCRVtyG0+iOO+5Q6nfffVepH3jggXHf/8EHHyj1a6+9ptR//PHHFEY3ddyGI9th4EgrBo604jZcBplb7C9dulSpzfvt8vLylNp8CaO5lYRu3IYj22HgSCsGjrTiNpyNXdyRAACuuko9QfvcuXNKXV9fr9QdHR3TMq7L4TYc2Q4DR1oxcKRVxls95JI777xTqR9//HGlrqmpUWrzNptZOBxW6oMHD05hdHpwCUdaMXCkFQNHWnEbzmJz585V6mAwaDw2t6hNt6NUPB5XavM1DdnQ/otLONKKgSOt0gpcY2MjampqUFhYiNLSUixbtizprsJnz55FIBDAddddh2uuuQYrVqxIalBIuSutY6kPPfQQVq5ciZqaGpw7dw6bNm1Cb28vwuGw0bZq/fr1+OqrrxAKheB2uxEMBuFwOPD999+n9B12P5Zq3u5atWqVUl+8zQYAlZWVk/4uc+sH8zUMX3zxxaQ/ezpY3q7r66+/VupQKITS0lJ0d3fj7rvvRjQaxUcffYSdO3fi/vvvB3D+JMJbb70VnZ2dWLhwYdJnsm1+bpnSNtyFhsolJSUAgO7ubvz7779K2/x58+bB6/WybT4BmELgEokENmzYgLvuusu4/C0SicDpdCadOs22+XTBpPfDBQIB9Pb24rvvvpvSAOzWNt98j4nbbrtNqd977z2lnjdv3qS/y3xL8rfeekup9+7dq9TZsJ9tIpNawgWDQezbtw/79+/HnDlzjOfLy8sxNjaW1AeNbfPpgrQCJyIIBoP4/PPP0d7ejqqqKmV+dXU1ZsyYobTN7+vrw/Hjx9k2nwCkuUoNBALYuXMn9u7di8LCQmO7zO12Y+bMmXC73VizZg2ee+45lJSUoKioCM888wxqa2sv+QuVck9a++HM10Ve0NLSgqeeegrA+R2/zz//PD777DOMjo6ivr4e27dvT3mVOt374S78or7A3K9jwYIFSn3jjTdO6ft++OEH4/E777yjzPvmm2+U+syZM1P6rkyzfD9cKtksKChAc3NzUn9aIoDHUkkzBo60uiLPh/P7/cbjjRs3KvN8Pp9S33DDDVP6rtOnTyt1U1OTUr/++uvG44luQZ4LuIQjrRg40uqKXKVe3Kr+4sepMF96t2/fPqU2t1cw7+owH2UhFZdwpBUDR1oxcKQV23WRZdiui2yHgSOtGDjSioEjrRg40oqBI60YONKKgSOtGDjSioEjrWwXOJsdaaM0pPK3s13ghoeHMz0EmqRU/na2O3ifSCRw4sQJiAi8Xi/6+/snPCBM/xeLxVBRUaH1301EMDw8DI/HA4dj/GWY7c74dTgcmDNnjtEnrqioiIGbBN3/bqme4WO7VSpd2Rg40sq2gXO5XNi8ebOtesdlA7v/u9nuRwNd2Wy7hKMrEwNHWjFwpBUDR1oxcKSVbQPX3NyMyspKFBQUwO/348iRI5kekm1k9T3PxIZaW1vF6XTKxx9/LEePHpW1a9dKcXGxDA4OZnpotlBfXy8tLS3S29srPT098vDDD4vX65WRkRHjNevWrZOKigppa2uTrq4uWbhwoSxatCiDoz7PloHz+XwSCASMOh6Pi8fjkcbGxgyOyr7+/PNPASAHDhwQEZGhoSGZMWOG7N6923jNL7/8IgDk0KFDmRqmiIjYbpU6NjaG7u5u5X5dDocDdXV1l71fV66z4p5nutgucCdPnkQ8Hk+6BdF49+vKZVbd80wX252eROmx6p5nuthuCTd79mzk5+cn/aLi/bqSZeM9z2wXOKfTierqauV+XYlEAm1tbbxf138km+95ltGfLJfR2toqLpdLQqGQhMNhaWhokOLiYolEIpkemi2sX79e3G63dHR0yMDAgDGdPn3aeM26devE6/VKe3u7dHV1SW1trdTW1mZw1OfZMnAiItu2bROv1ytOp1N8Pp90dnZmeki2AeCSU0tLi/GaM2fOyNNPPy3XXnutzJo1S5YvXy4DAwOZG/R/eD4caWW7bTi6sjFwpBUDR1oxcKQVA0daMXCkFQNHWjFwpBUDR1oxcKQVA0da/Q98JD3lgdzW7wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See if the data is usable\n",
    "for i in range(3):  \n",
    "    plt.subplot(330 + 1 + i)\n",
    "    plt.imshow(train_X[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.show()\n",
    "\n",
    "train_X[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def train(model, xs, ys, epochs, iterPerEpoch, lr):\n",
      "(60000, 784, 1)\n"
     ]
    }
   ],
   "source": [
    "from Engine.MultiLayerPerceptron import train\n",
    "\n",
    "print(\"def train(model, xs, ys, epochs, iterPerEpoch, lr):\")\n",
    "\n",
    "def reshapeImage(image):\n",
    "    return np.reshape(image, (image.shape[0] * image.shape[1], 1))\n",
    "\n",
    "def flattenData(inputImages):\n",
    "    outputImages = []\n",
    "    \"\"\"Enter Input Images as an array full of images\"\"\"\n",
    "    for i in range(inputImages.shape[0]):\n",
    "        outputImages.append(reshapeImage(inputImages[i]))\n",
    "        \n",
    "    return np.array(outputImages)\n",
    "    \n",
    "    \n",
    "images = flattenData(train_X)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages = flattenData(train_X)\n",
    "trainLabels = train_y\n",
    "\n",
    "model1 = MLP(784, [128, 64, 10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcLoss(modelPred, Actual):\n",
    "    predArray = np.zeros(10)\n",
    "    predArray[Actual] = 1\n",
    "    loss = 0\n",
    "    \n",
    "    for i, out in enumerate(modelPred):\n",
    "        loss += (out.data - predArray[i])**2\n",
    "    \n",
    "    return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss(model, batch_size=None):\n",
    "    \n",
    "\n",
    "    inputs = [list(map(Value, xrow)) for xrow in trainImages]\n",
    "    \n",
    "    # forward the model to get scores\n",
    "    scores = list(map(model, inputs))\n",
    "    \n",
    "    # svm \"max-margin\" loss\n",
    "    losses = [(1 + -yi*scorei).relu() for yi, scorei in zip(, scores)]\n",
    "    data_loss = sum(losses) * (1.0 / len(losses))\n",
    "    # L2 regularization\n",
    "    alpha = 1e-4\n",
    "    reg_loss = alpha * sum((p*p for p in model.parameters()))\n",
    "    total_loss = data_loss + reg_loss\n",
    "    \n",
    "    # also get accuracy\n",
    "    accuracy = [(yi > 0) == (scorei.data > 0) for yi, scorei in zip(yb, scores)]\n",
    "    return total_loss, sum(accuracy) / len(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(model, image):\n",
    "    highestPred = -1\n",
    "    prediction = -1\n",
    "    for i, out in enumerate(model(image)):\n",
    "        if out.value > highestPred:\n",
    "            highestPred = out.value\n",
    "            prediction = i\n",
    "        \n",
    "    if highestPred == -1:\n",
    "        return \"Error\"\n",
    "    else:\n",
    "        return prediction\n",
    "\n",
    "prediction = model1(trainImages[1])\n",
    "actual = trainLabels[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.2212136e+09]\n"
     ]
    }
   ],
   "source": [
    "loss = calcLoss(prediction, actual)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def trainMNIST(model, images, labels, epochs, BatchSize, lr):\n",
    "    \"\"\"\n",
    "    def train(model, xs, ys, epochs, iterPerEpoch, lr):\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialLoss = sum((yOut + (-yGroundTruth)) ** 2 for yGroundTruth, yOut in zip(ys, [model(x) for x in xs]))\n",
    "    \n",
    "    print(\"\\n\\033[1;33mTraining: \\n------------------------\\033[0m\")\n",
    "    for i in range(epochs):\n",
    "        avgLoss = 0\n",
    "        \n",
    "        Batches = tqdm(range(BatchSize))\n",
    "        for k in Batches:            \n",
    "            predictions = model(images[(i * BatchSize + k)])\n",
    "            loss = Value(calcLoss(predictions, labels[i * BatchSize + k]))\n",
    "            loss.label = \"Loss\"\n",
    "            \n",
    "            avgLoss += loss.data\n",
    "            \n",
    "            for param in model.parameters():\n",
    "                param.grad = 0.0 # Zero the gradient\n",
    "                \n",
    "            loss.backward() # Back Propagation\n",
    "            \n",
    "            for param in model.parameters():\n",
    "                param.data +=  param.grad * -lr # Update the parameters by a small factor\n",
    "            \n",
    "            avgLoss /= (k+1)\n",
    "            Batches.set_description(f\"Epoch {i+1}\")\n",
    "            Batches.set_postfix({'avgLoss': avgLoss})\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def trainMNIST(model, images, labels, epochs, BatchSize, lr):\n",
    "        \n",
    "    print(\"\\n\\033[1;33mTraining: \\n------------------------\\033[0m\")\n",
    "    for i in range(epochs):\n",
    "        avgLoss = 0\n",
    "        \n",
    "        Batches = tqdm(range(BatchSize))\n",
    "        for k in Batches:            \n",
    "            predictions = model(images[(i * BatchSize + k)])\n",
    "            loss = Value(calcLoss(predictions, labels[i * BatchSize + k]))\n",
    "            loss.label = \"Loss\"\n",
    "            \n",
    "            avgLoss += loss.data\n",
    "            \n",
    "            for param in model.parameters():\n",
    "                param.grad = 0.0 # Zero the gradient\n",
    "                \n",
    "            loss.backward() # Back Propagation\n",
    "            \n",
    "            for param in model.parameters():\n",
    "                param.data +=  param.grad * -lr # Update the parameters by a small factor\n",
    "            \n",
    "            avgLoss /= (k+1)\n",
    "            Batches.set_description(f\"Epoch {i+1}\")\n",
    "            Batches.set_postfix({'avgLoss': avgLoss})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimization\n",
    "for k in range(100):\n",
    "    \n",
    "    # forward\n",
    "    total_loss, acc = loss()\n",
    "    \n",
    "    # backward\n",
    "    model.zero_grad()\n",
    "    total_loss.backward()\n",
    "    \n",
    "    # update (sgd)\n",
    "    learning_rate = 1.0 - 0.9*k/100\n",
    "    for p in model.parameters():\n",
    "        p.data -= learning_rate * p.grad\n",
    "    \n",
    "    if k % 1 == 0:\n",
    "        print(f\"step {k} loss {total_loss.data}, accuracy {acc*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = MLP(784, [512, 128, 64, 10])\n",
    "\n",
    "for neuron in model2.layers[1].parameters():\n",
    "    neuron.activation = 'relu'\n",
    "for neuron in model2.layers[2].parameters():\n",
    "    neuron.activation = 'relu'\n",
    "for neuron in model2.layers[3].parameters():\n",
    "    neuron.activation = 'tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1;33mTraining: \n",
      "------------------------\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   2%|‚ñè         | 1/50 [00:36<30:11, 36.96s/it, avgLoss=[1.10382243e+12]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[84], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainMNIST(model2, trainImages, trainLabels, \u001b[39m50\u001b[39;49m, \u001b[39m50\u001b[39;49m, \u001b[39m0.1\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[82], line 16\u001b[0m, in \u001b[0;36mtrainMNIST\u001b[0;34m(model, images, labels, epochs, BatchSize, lr)\u001b[0m\n\u001b[1;32m     14\u001b[0m Batches \u001b[39m=\u001b[39m tqdm(\u001b[39mrange\u001b[39m(BatchSize))\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m Batches:            \n\u001b[0;32m---> 16\u001b[0m     predictions \u001b[39m=\u001b[39m model(images[(i \u001b[39m*\u001b[39;49m BatchSize \u001b[39m+\u001b[39;49m k)])\n\u001b[1;32m     17\u001b[0m     loss \u001b[39m=\u001b[39m Value(calcLoss(predictions, labels[i \u001b[39m*\u001b[39m BatchSize \u001b[39m+\u001b[39m k]))\n\u001b[1;32m     18\u001b[0m     loss\u001b[39m.\u001b[39mlabel \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mLoss\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:153\u001b[0m, in \u001b[0;36mMLP.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m    152\u001b[0m     \u001b[39mfor\u001b[39;00m layer \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[0;32m--> 153\u001b[0m         x \u001b[39m=\u001b[39m layer(x)\n\u001b[1;32m    154\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:136\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 136\u001b[0m     out \u001b[39m=\u001b[39m [n(x) \u001b[39mfor\u001b[39;49;00m n \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mneurons]\n\u001b[1;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:136\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 136\u001b[0m     out \u001b[39m=\u001b[39m [n(x) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mneurons]\n\u001b[1;32m    137\u001b[0m     \u001b[39mreturn\u001b[39;00m out[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m out\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:121\u001b[0m, in \u001b[0;36mNeuron.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 121\u001b[0m     act \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m((wi\u001b[39m*\u001b[39mxi \u001b[39mfor\u001b[39;00m wi,xi \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw, x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m act\u001b[39m.\u001b[39mrelu() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnonlin \u001b[39melse\u001b[39;00m act\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:121\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m--> 121\u001b[0m     act \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m((wi\u001b[39m*\u001b[39;49mxi \u001b[39mfor\u001b[39;00m wi,xi \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw, x)), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mb)\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m act\u001b[39m.\u001b[39mrelu() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnonlin \u001b[39melse\u001b[39;00m act\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:34\u001b[0m, in \u001b[0;36mValue.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__mul__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m     33\u001b[0m     other \u001b[39m=\u001b[39m other \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Value) \u001b[39melse\u001b[39;00m Value(other)\n\u001b[0;32m---> 34\u001b[0m     out \u001b[39m=\u001b[39m Value(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata \u001b[39m*\u001b[39;49m other\u001b[39m.\u001b[39;49mdata, (\u001b[39mself\u001b[39;49m, other), \u001b[39m'\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     36\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_backward\u001b[39m():\n\u001b[1;32m     37\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgrad \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m other\u001b[39m.\u001b[39mdata \u001b[39m*\u001b[39m out\u001b[39m.\u001b[39mgrad\n",
      "File \u001b[0;32m~/Desktop/CS Gross/Python ew/MNIST-classifier-from-scratch/Engine/Engine.py:18\u001b[0m, in \u001b[0;36mValue.__init__\u001b[0;34m(self, data, _children, _op)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# internal variables used for autograd graph construction\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m: \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prev \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(_children)\n\u001b[1;32m     19\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_op \u001b[39m=\u001b[39m _op\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainMNIST(model2, trainImages, trainLabels, 50, 50, 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
